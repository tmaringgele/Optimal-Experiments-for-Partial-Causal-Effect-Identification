{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f17314",
   "metadata": {},
   "source": [
    "### Example Setup: Fully Confounded IV\n",
    "\n",
    "**DAG**\n",
    "- Z → X → Y\n",
    "- U → {Z, X, Y} (U unobserved; allows arbitrary confounding)\n",
    "\n",
    "**Target**\n",
    "$$\n",
    "P(Y=1 \\mid do(X=1))\n",
    "$$\n",
    "\n",
    "**Experiments (cost 1 each), Budget B = 1**\n",
    "- Z1: observe $P(X=1 \\mid do(Z=1))$\n",
    "- Z0: observe $P(X=1 \\mid do(Z=0))$\n",
    "\n",
    "**LP decision variables (response-type with instrument):**\n",
    "$$\n",
    "q_{z,x_0,x_1,y_0,y_1}\n",
    "= \\Pr\\!\\big(Z=z,\\; X(0)=x_0,\\; X(1)=x_1,\\; Y(0)=y_0,\\; Y(1)=y_1\\big),\n",
    "\\quad z,x_0,x_1,y_0,y_1\\in\\{0,1\\}.\n",
    "$$\n",
    "- Total variables: $2^5 = 32$.\n",
    "- Normalization & nonnegativity: $\\sum q_{z,x_0,x_1,y_0,y_1}=1,\\; q\\ge 0$.\n",
    "\n",
    "**Target as a linear form in $q$:**\n",
    "$$\n",
    "P(Y=1 \\mid do(X=1))\n",
    "= \\sum_{z,x_0,x_1,y_0,y_1:\\; y_1=1} q_{z,x_0,x_1,y_0,y_1}.\n",
    "$$\n",
    "\n",
    "**Observational consistency (if used):**\n",
    "$$\n",
    "P(Z=z, X=x, Y=y)\n",
    "= \\sum_{x_0,x_1,y_0,y_1:\\; x = x_z,\\; y = y_x} q_{z,x_0,x_1,y_0,y_1}.\n",
    "$$\n",
    "\n",
    "**Interventional constraints for experiments:**\n",
    "Let $\\tilde q_{x_0,x_1,y_0,y_1} := \\sum_{z'} q_{z',x_0,x_1,y_0,y_1}$. Then\n",
    "$$\n",
    "P(X=1 \\mid do(Z=z))\n",
    "= \\sum_{x_0,x_1,y_0,y_1:\\; x_z=1} \\tilde q_{x_0,x_1,y_0,y_1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic data (sample joint directly)\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.special import expit\n",
    "\n",
    "def create_consistent_observational_data(seed=42):\n",
    "    \"\"\"\n",
    "    Create observational data that's guaranteed to be consistent\n",
    "    by construction from a simple response-type distribution\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING CONSISTENT OBSERVATIONAL DATA BY CONSTRUCTION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    np.random.seed(seed)  # Set seed for reproducibility\n",
    "\n",
    "    # Define a simple response-type distribution manually\n",
    "    variables = list(itertools.product([0,1], [0,1], [0,1], [0,1], [0,1]))\n",
    "    n_vars = len(variables)\n",
    "    \n",
    "    # Create a simple uniform-ish distribution over response types\n",
    "    q_true = np.ones(n_vars) / n_vars  # Uniform distribution\n",
    "    \n",
    "    # Alternatively, create a more interesting distribution\n",
    "    q_true = np.random.dirichlet(np.ones(n_vars))  # Random but valid distribution\n",
    "    \n",
    "    print(f\"True response-type distribution (first 5 components):\")\n",
    "    for i in range(5):\n",
    "        z, x0, x1, y0, y1 = variables[i]\n",
    "        print(f\"  q[{i}] = {q_true[i]:.4f}: (z={z}, x0={x0}, x1={x1}, y0={y0}, y1={y1})\")\n",
    "    \n",
    "    # Now compute the implied observational distribution\n",
    "    obs_probs = {}\n",
    "    for z_obs in [0, 1]:\n",
    "        for x_obs in [0, 1]:\n",
    "            for y_obs in [0, 1]:\n",
    "                prob = 0.0\n",
    "                \n",
    "                for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "                    # Check if this response type contributes\n",
    "                    if z == z_obs:\n",
    "                        x_potential = x1 if z_obs == 1 else x0\n",
    "                        if x_potential == x_obs:\n",
    "                            y_potential = y1 if x_obs == 1 else y0\n",
    "                            if y_potential == y_obs:\n",
    "                                prob += q_true[i]\n",
    "                \n",
    "                obs_probs[(z_obs, x_obs, y_obs)] = prob\n",
    "    \n",
    "    print(f\"\\nImplied observational distribution:\")\n",
    "    total_prob = 0\n",
    "    for key, prob in obs_probs.items():\n",
    "        print(f\"  P{key} = {prob:.4f}\")\n",
    "        total_prob += prob\n",
    "    print(f\"  Total probability: {total_prob:.4f}\")\n",
    "    \n",
    "    # Compute experimental result P(X=1|do(Z=1))\n",
    "    exp_prob = 0.0\n",
    "    for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "        if z == 1 and x1 == 1:  # Z=1 and X(1)=1\n",
    "            exp_prob += q_true[i]\n",
    "    \n",
    "    print(f\"\\nImplied experimental result:\")\n",
    "    print(f\"  P(X=1|do(Z=1)) = {exp_prob:.4f}\")\n",
    "    \n",
    "    return obs_probs, exp_prob, q_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a8ed2b",
   "metadata": {},
   "source": [
    "# Example: LB under Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08dc9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.special import expit\n",
    "\n",
    "def fix_observational_constraint_mapping():\n",
    "    \"\"\"\n",
    "    The issue is in how we map P(Z,X,Y) to response-type variables q[z,x0,x1,y0,y1]\n",
    "    \n",
    "    Key insight: P(Z=z, X=x, Y=y) should equal the sum of all q[z',x0,x1,y0,y1] where:\n",
    "    - The observed Z=z (this selects z'=z)  \n",
    "    - The observed X=x matches the response X(z) = x_z\n",
    "    - The observed Y=y matches the response Y(x) = y_x\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"FIXING OBSERVATIONAL CONSTRAINT MAPPING\")  \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Let's trace through the logic step by step\n",
    "    variables = list(itertools.product([0,1], [0,1], [0,1], [0,1], [0,1]))\n",
    "    print(f\"Total variables: {len(variables)}\")\n",
    "    print(\"Variable format: (z, x0, x1, y0, y1)\")\n",
    "    print(\"  z: observed instrument\")\n",
    "    print(\"  x0, x1: potential responses of X under Z=0, Z=1\") \n",
    "    print(\"  y0, y1: potential responses of Y under X=0, X=1\")\n",
    "    \n",
    "    # Example: P(Z=1, X=0, Y=1) \n",
    "    # This means we observed Z=1, X=0, Y=1\n",
    "    z_obs, x_obs, y_obs = 1, 0, 1\n",
    "    print(f\"\\nAnalyzing: P(Z={z_obs}, X={x_obs}, Y={y_obs})\")\n",
    "    \n",
    "    contributing_vars = []\n",
    "    for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "        # For this observation to be possible from this response type:\n",
    "        \n",
    "        # 1. The instrument must match: z == z_obs\n",
    "        if z != z_obs:\n",
    "            continue\n",
    "            \n",
    "        # 2. The observed X must match the potential response under the observed Z\n",
    "        # If Z=1 was observed, then X must equal x1 (response under Z=1)\n",
    "        # If Z=0 was observed, then X must equal x0 (response under Z=0)\n",
    "        x_potential = x1 if z_obs == 1 else x0\n",
    "        if x_potential != x_obs:\n",
    "            continue\n",
    "            \n",
    "        # 3. The observed Y must match the potential response under the observed X\n",
    "        # If X=1 was observed, then Y must equal y1 (response under X=1)\n",
    "        # If X=0 was observed, then Y must equal y0 (response under X=0)  \n",
    "        y_potential = y1 if x_obs == 1 else y0\n",
    "        if y_potential != y_obs:\n",
    "            continue\n",
    "            \n",
    "        # If we get here, this response type contributes to the observed probability\n",
    "        contributing_vars.append((i, z, x0, x1, y0, y1))\n",
    "    \n",
    "    print(f\"Contributing response types:\")\n",
    "    for i, z, x0, x1, y0, y1 in contributing_vars:\n",
    "        print(f\"  q[{i}]: (z={z}, x0={x0}, x1={x1}, y0={y0}, y1={y1})\")\n",
    "        \n",
    "        # Verify the logic\n",
    "        x_under_z = x1 if z == 1 else x0\n",
    "        y_under_x = y1 if x_obs == 1 else y0  \n",
    "        print(f\"    -> Z={z}, X(Z={z})={x_under_z}, Y(X={x_obs})={y_under_x}\")\n",
    "    \n",
    "    return contributing_vars\n",
    "\n",
    "\n",
    "\n",
    "def test_fixed_lp(obs_probs, p_val, q_true):\n",
    "    \"\"\"\n",
    "    Test the LP with consistent data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TESTING LP WITH p = {p_val}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Set up variables\n",
    "    variables = list(itertools.product([0,1], [0,1], [0,1], [0,1], [0,1]))\n",
    "    n_vars = len(variables)\n",
    "    \n",
    "    q = cp.Variable(n_vars, nonneg=True)\n",
    "    p = cp.Parameter()\n",
    "    \n",
    "    # Target: P(Y=1|do(X=1))\n",
    "    theta = np.zeros(n_vars)\n",
    "    for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "        if y1 == 1:\n",
    "            theta[i] = 1.0\n",
    "    \n",
    "    # Experimental constraint\n",
    "    experiment_coeff = np.zeros(n_vars)\n",
    "    for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "        if z == 1 and x1 == 1:\n",
    "            experiment_coeff[i] = 1.0\n",
    "    \n",
    "    # Observational constraints (using corrected mapping)\n",
    "    obs_constraints = []\n",
    "    for (z_obs, x_obs, y_obs), observed_prob in obs_probs.items():\n",
    "        obs_coeff = np.zeros(n_vars)\n",
    "        \n",
    "        for i, (z, x0, x1, y0, y1) in enumerate(variables):\n",
    "            if z == z_obs:  # Instrument matches\n",
    "                x_potential = x1 if z_obs == 1 else x0  # X response under observed Z\n",
    "                if x_potential == x_obs:\n",
    "                    y_potential = y1 if x_obs == 1 else y0  # Y response under observed X\n",
    "                    if y_potential == y_obs:\n",
    "                        obs_coeff[i] = 1.0\n",
    "        \n",
    "        obs_constraints.append(obs_coeff @ q == observed_prob)\n",
    "    \n",
    "    # All constraints\n",
    "    constraints = [\n",
    "        cp.sum(q) == 1,  # normalization\n",
    "        experiment_coeff @ q == p,  # experiment\n",
    "        *obs_constraints  # observations\n",
    "    ]\n",
    "    \n",
    "    print(f\"LP setup:\")\n",
    "    print(f\"  Variables: {n_vars}\")\n",
    "    print(f\"  Constraints: {len(constraints)} total\")\n",
    "    print(f\"    - 1 normalization\")\n",
    "    print(f\"    - 1 experimental\") \n",
    "    print(f\"    - {len(obs_constraints)} observational\")\n",
    "    \n",
    "    # Test feasibility\n",
    "    p.value = p_val\n",
    "    test_problem = cp.Problem(cp.Minimize(0), constraints)\n",
    "    test_problem.solve()\n",
    "    \n",
    "    print(f\"\\nFeasibility test: {test_problem.status}\")\n",
    "    \n",
    "    if test_problem.status == cp.OPTIMAL:\n",
    "        print(\"✅ LP is feasible!\")\n",
    "        \n",
    "        # Test bounds\n",
    "        lb_problem = cp.Problem(cp.Minimize(theta @ q), constraints)\n",
    "        ub_problem = cp.Problem(cp.Maximize(theta @ q), constraints)\n",
    "        \n",
    "        lb_problem.solve()\n",
    "        ub_problem.solve()\n",
    "        \n",
    "        if lb_problem.status == cp.OPTIMAL and ub_problem.status == cp.OPTIMAL:\n",
    "            lb = lb_problem.value\n",
    "            ub = ub_problem.value\n",
    "            \n",
    "            # Compute true target value\n",
    "            true_target = theta @ q_true\n",
    "            \n",
    "            print(f\"\\nBounds on P(Y=1|do(X=1)):\")\n",
    "            print(f\"  Lower bound: {lb:.4f}\")\n",
    "            print(f\"  Upper bound: {ub:.4f}\")\n",
    "            print(f\"  Width: {ub - lb:.4f}\")\n",
    "            print(f\"  True value: {true_target:.4f}\")\n",
    "            print(f\"  True in bounds? {lb <= true_target <= ub}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ Bounds computation failed\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"❌ LP is still infeasible\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9b40a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING CONSISTENT OBSERVATIONAL DATA BY CONSTRUCTION\n",
      "============================================================\n",
      "True response-type distribution (first 5 components):\n",
      "  q[0] = 0.0076: (z=0, x0=0, x1=0, y0=0, y1=0)\n",
      "  q[1] = 0.0412: (z=0, x0=0, x1=0, y0=0, y1=1)\n",
      "  q[2] = 0.0205: (z=0, x0=0, x1=0, y0=1, y1=0)\n",
      "  q[3] = 0.0175: (z=0, x0=0, x1=0, y0=1, y1=1)\n",
      "  q[4] = 0.0087: (z=0, x0=0, x1=1, y0=0, y1=0)\n",
      "\n",
      "Implied observational distribution:\n",
      "  P(0, 0, 0) = 0.0607\n",
      "  P(0, 0, 1) = 0.0894\n",
      "  P(0, 1, 0) = 0.1136\n",
      "  P(0, 1, 1) = 0.2134\n",
      "  P(1, 0, 0) = 0.1806\n",
      "  P(1, 0, 1) = 0.1562\n",
      "  P(1, 1, 0) = 0.0755\n",
      "  P(1, 1, 1) = 0.1107\n",
      "  Total probability: 1.0000\n",
      "\n",
      "Implied experimental result:\n",
      "  P(X=1|do(Z=1)) = 0.1862\n",
      "\n",
      "============================================================\n",
      "TESTING LP WITH p = 0.2197\n",
      "============================================================\n",
      "LP setup:\n",
      "  Variables: 32\n",
      "  Constraints: 10 total\n",
      "    - 1 normalization\n",
      "    - 1 experimental\n",
      "    - 8 observational\n",
      "\n",
      "Feasibility test: infeasible\n",
      "❌ LP is still infeasible\n",
      "\n",
      "============================================================\n",
      "TESTING LP WITH p = 0.15\n",
      "============================================================\n",
      "LP setup:\n",
      "  Variables: 32\n",
      "  Constraints: 10 total\n",
      "    - 1 normalization\n",
      "    - 1 experimental\n",
      "    - 8 observational\n",
      "\n",
      "Feasibility test: infeasible\n",
      "❌ LP is still infeasible\n"
     ]
    }
   ],
   "source": [
    "obs_probs, true_exp_result, q_true = create_consistent_observational_data()\n",
    "\n",
    "p_vals = [0.2197, 0.15]\n",
    "for p_val in p_vals:\n",
    "    test_fixed_lp(obs_probs, p_val, q_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
