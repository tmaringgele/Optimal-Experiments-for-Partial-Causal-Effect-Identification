# Verification of Sachs et al. (2022) Section 6 Examples

## Summary

This document summarizes the verification of the dual LP approach for computing symbolic bounds on causal effects, as described in Sachs et al. (2022) "A General Method for Deriving Tight Symbolic Bounds on Causal Effects".

## What Was Implemented

### 1. Dual LP Approach (‚úÖ Complete)
- **File**: `test_dual_clean.py`
- **Status**: Fully working implementation
- **Method**: Uses `pycddlib` for vertex enumeration in dual space
- **Result**: Successfully computes symbolic bounds as linear combinations of observed parameters

### 2. Section 6.1: Confounded Exposure and Outcome

#### Binary Case (‚úÖ Verified)
- **File**: `verify_section6_1.py`
- **Setup**: X, Y ‚àà {0,1} with unobserved confounder U
- **Query**: Average Treatment Effect (ATE) = P{Y(X=1)=1} - P{Y(X=0)=1}
- **Result**: Successfully derived **Balke-Pearl bounds**:
  - **Lower bound**: `p{X=1,Y=1} + p{X=0,Y=0} - 1`
  - **Upper bound**: `1 - p{X=1,Y=0} - p{X=0,Y=1}`

**Numerical Example**:
```
Given: p(X=0,Y=0) = 0.3, p(X=0,Y=1) = 0.2, p(X=1,Y=0) = 0.1, p(X=1,Y=1) = 0.4
Bounds: [-0.30, 0.70]
```

#### Ternary Case (‚ö†Ô∏è Pending)
- **Setup**: X ‚àà {0,1,2}, Y ‚àà {0,1}
- **Parameters**: 6 observed probabilities (3√ó2)
- **Query**: Risk difference P{Y(X=x‚ÇÅ)=1} - P{Y(X=x‚ÇÇ)=1}
- **Expected Bounds** (from paper):
  ```
  p{X=x‚ÇÅ,Y=1} + p{X=x‚ÇÇ,Y=0} - 1 
    ‚â§ p{Y(X=x‚ÇÅ)=1} - p{Y(X=x‚ÇÇ)=1} ‚â§ 
  1 - p{X=x‚ÇÅ,Y=0} - p{X=x‚ÇÇ,Y=1}
  ```
- **Status**: Formula documented, implementation pending
- **Requirements**: 
  - Extend response type enumeration to handle ternary variables
  - Generate constraint matrix for 3√ó2 case

### 3. Section 6.2: Two Instruments (üìã Documented)
- **File**: `test_section6_examples.py`
- **Setup**: Z‚ÇÅ, Z‚ÇÇ ‚Üí X ‚Üí Y (all binary)
- **Complexity**: 
  - 16 constraints (conditional probabilities)
  - 64 parameters (response function distribution)
  - 112 vertices in dual polytope
- **Query**: P{Y(X=1)=1} - P{Y(X=0)=1}
- **Status**: Paper notes bounds are too long to present simply
- **Note**: Code for this example is in supplementary materials

### 4. Section 6.3: Measurement Error (üìã Documented)
- **File**: `test_section6_examples.py`
- **Setup**: X ‚Üí Y ‚Üí Y‚ÇÇ, where Y is unobserved
- **Constraint**: Monotonicity Y‚ÇÇ(Y=1) ‚â• Y‚ÇÇ(Y=0)
- **Parameters**: 12 parameters, 4 constraints
- **Query**: P{Y(X=1)=1} - P{Y(X=0)=1}
- **Expected Bounds** (from paper):
  ```
  max{-1, 2¬∑p{Y‚ÇÇ=0|X=0} - 2¬∑p{Y‚ÇÇ=0|X=1} - 1}
    ‚â§ P{Y(X=1)=1} - P{Y(X=0)=1} ‚â§
  min{1, 2¬∑p{Y‚ÇÇ=0|X=0} - 2¬∑p{Y‚ÇÇ=0|X=1} + 1}
  ```
- **Status**: Formula documented, implementation pending
- **Requirements**:
  - Handle latent variables (Y unobserved)
  - Implement monotonicity constraints

## Key Achievements

### ‚úÖ Completed
1. **Dual LP Implementation**: Working code in `test_dual_clean.py`
2. **Binary Confounding**: Verified Balke-Pearl bounds match Section 6.1
3. **Documentation**: All three Section 6 examples documented with expected formulas
4. **Numerical Verification**: Confirmed bounds are valid with concrete distributions

### ‚ö†Ô∏è In Progress
1. **Ternary Variables**: Need to extend response type enumeration
2. **Constraint Generation**: Automate constraint matrix construction for general DAGs

### üìã Future Work
1. **Two Instruments**: Implement full 112-vertex enumeration
2. **Measurement Error**: Add support for latent variables and monotonicity constraints
3. **General Framework**: Integrate with existing `symbolic_bounds` package

## Technical Details

### Method: Dual LP Approach

The dual LP method transforms the problem of finding symbolic bounds:

**Primal LP**:
```
maximize/minimize: c^T Œ∏
subject to: A Œ∏ = p
            Œ∏ ‚â• 0
```

**Dual LP**:
```
maximize/minimize: p^T y
subject to: A^T y ‚â§ c  (for max)
            A^T y ‚â• c  (for min)
```

Where:
- `Œ∏`: response function distribution (hidden parameters)
- `p`: observed distribution parameters
- `c`: causal query coefficients
- `A`: constraint matrix relating Œ∏ to p

The symbolic bounds are found by:
1. Enumerating vertices of the dual feasible region using `pycddlib`
2. Computing `p^T y` for each vertex y
3. Taking max/min over vertices to get upper/lower bounds

### Key Formula (Balke-Pearl Bounds)

For binary confounded X‚ÜíY, the ATE bounds are:

```python
lower = p11 + p00 - 1
upper = 1 - p10 - p01
```

This is a special case of the general formula from Section 6.1:
```
p{X=x‚ÇÅ,Y=1} + p{X=x‚ÇÇ,Y=0} - 1 ‚â§ ATE ‚â§ 1 - p{X=x‚ÇÅ,Y=0} - p{X=x‚ÇÇ,Y=1}
```

## Files

### Implementation Files
- `test_dual_clean.py`: Main dual LP implementation (‚úÖ working)
- `verify_section6_1.py`: Section 6.1 binary case verification (‚úÖ working)
- `test_section6_examples.py`: Documentation of all Section 6 examples (üìã reference)

### Supporting Files
- `section6.md`: Paper content provided by user
- `symbolic_bounds/`: Package with DAG, node, LP construction tools
- `VERTEX_ENUMERATION_SUMMARY.md`: Documentation of vertex enumeration approach

## References

Sachs, M. C., et al. (2022). "A General Method for Deriving Tight Symbolic Bounds on Causal Effects." *Journal of Causal Inference*, 10(1), 223-245.

## Next Steps

1. **Extend to ternary variables**: Modify response type enumeration in `symbolic_bounds/response_type.py`
2. **Automate constraint generation**: Use `symbolic_bounds/program_factory.py` to generate A matrix
3. **Integrate with dual solver**: Connect ProgramFactory output to `test_dual_clean.py` solver
4. **Test on all Section 6 examples**: Verify symbolic results match paper formulas

## Conclusion

The dual LP approach has been successfully implemented and verified for the binary confounded case (Section 6.1). The results match the expected Balke-Pearl bounds. The method is general and can be extended to handle:
- Ternary and higher-cardinality variables
- Multiple instruments
- Latent variables
- Additional constraints (monotonicity, etc.)

The core algorithm is working correctly. Remaining work is primarily engineering: automating constraint generation and extending response type enumeration to handle more complex scenarios.
