{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472ec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autobound.causalProblem import causalProblem\n",
    "from autobound.DAG import DAG\n",
    "from autobound.Query import Query\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097243f",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Find a $Z \\subseteq V$ s.t. $Z$ is outside of any Hedge for some $Q$, but $pot_Q(Z) > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97cb6a2",
   "metadata": {},
   "source": [
    "## DAG 0\n",
    "$Z \\to X \\to Y$\n",
    "\n",
    "$X \\leftrightarrow Y$, $Z \\leftrightarrow Y$\n",
    "\n",
    "$Z$ is inside the Hedge. I still want to know if $pot(Z) > 0$\n",
    "\n",
    "*Result:* $pot(Z) > 0$ ($do(Z)$ even identifies Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a135e68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth  P(Y=1 | do(X=1))  = 0.499\n",
      "[OBS only]  P(Y=1 | do(X=1)) ∈ [0.2492, 0.7505]\n",
      "W = 0.5013\n",
      "[OBS + do(Z)] P(Y=1 | do(X=1)) ∈ [0.4990, 0.4990]\n",
      "W = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) Synthetic SCM for: Z -> X -> Y; U_XY -> {X,Y}; U_ZY -> {Z,Y} ----------\n",
    "def synth_scm_Z_X_Y(n=20, p=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      obs  : P[z,x,y]     (shape (2,2,2))\n",
    "      doZ  : dict z -> P[x,y | do(Z=z)]  (each shape (2,2))\n",
    "      p_y1_do_x1 : ground-truth P(Y=1 | do(X=1))\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Exogenous latents (independent Bernoulli(p))\n",
    "    U_XY = rng.binomial(1, p, n)\n",
    "    U_ZY = rng.binomial(1, p, n)\n",
    "\n",
    "    # Structural (boolean) equations consistent with the DAG\n",
    "    # Z depends on U_ZY (to realize Z<->Y without a directed Z->Y)\n",
    "    Z = U_ZY.astype(int)\n",
    "\n",
    "    # X depends on Z and U_XY (Z->X and X<->Y through U_XY)\n",
    "    #   X = Z XOR U_XY\n",
    "    X = np.logical_xor(Z, U_XY).astype(int)\n",
    "\n",
    "    # Y depends on X, U_XY, U_ZY (X->Y, X<->Y, Z<->Y)\n",
    "    #   Y = (X OR U_XY) XOR U_ZY\n",
    "    Y = np.logical_xor(np.logical_or(X, U_XY), U_ZY).astype(int)\n",
    "\n",
    "    def joint_prob(*cols, dims):\n",
    "        idx = np.ravel_multi_index(cols, dims)\n",
    "        counts = np.bincount(idx, minlength=np.prod(dims)).reshape(dims)\n",
    "        return counts / counts.sum()\n",
    "\n",
    "    # Observational P(Z,X,Y)\n",
    "    obs = joint_prob(Z, X, Y, dims=(2,2,2))   # P[z,x,y]\n",
    "\n",
    "    # do(Z=z): set Z=z, recompute downstream\n",
    "    doZ = {}\n",
    "    for z in (0, 1):\n",
    "        Z_do = np.full(n, z, dtype=int)\n",
    "        X_do = np.logical_xor(Z_do, U_XY).astype(int)\n",
    "        Y_do = np.logical_xor(np.logical_or(X_do, U_XY), U_ZY).astype(int)\n",
    "        doZ[z] = joint_prob(X_do, Y_do, dims=(2,2))  # P[x,y | do(Z=z)]\n",
    "\n",
    "    # Ground truth P(Y=1 | do(X=1)): set X=1, compute Y = (1 OR U_XY) XOR U_ZY = 1 XOR U_ZY\n",
    "    Y_doX1 = np.logical_xor(1, U_ZY).astype(int)\n",
    "    p_y1_do_x1 = Y_doX1.mean()  # = P(U_ZY=0) = 1 - p for this choice\n",
    "\n",
    "    return obs, doZ, p_y1_do_x1\n",
    "\n",
    "# ---------- 2) Build the ADMG in autobound ----------\n",
    "dag = DAG()\n",
    "dag.from_structure(\n",
    "    \"Z -> X, X -> Y, \"\n",
    "    \"U_XY -> X, U_XY -> Y, \"   # X <-> Y\n",
    "    \"U_ZY -> Z, U_ZY -> Y\",    # Z <-> Y\n",
    "    unob=\"U_XY,U_ZY\"\n",
    ")\n",
    "\n",
    "# Generate synthetic distributions\n",
    "obs_tab, doZ_tabs, pstar = synth_scm_Z_X_Y(n=300_000, p=0.5, seed=np.random.randint(1_000_000))\n",
    "print(\"Ground truth  P(Y=1 | do(X=1))  =\", round(float(pstar), 4))\n",
    "\n",
    "# ---------- 3) Problem A: observational only ----------\n",
    "obs_only = causalProblem(dag, number_values={'Z':2,'X':2,'Y':2})\n",
    "\n",
    "# Add P(Z,X,Y) from the array (no CSV)\n",
    "for z in (0, 1):\n",
    "    for x in (0, 1):\n",
    "        for y in (0, 1):\n",
    "            p = float(obs_tab[z, x, y])\n",
    "            obs_only.add_constraint(obs_only.query(f'Z={z}&X={x}&Y={y}') - Query(p))\n",
    "\n",
    "# Add simplex constraints over response-function blocks\n",
    "obs_only.add_prob_constraints()\n",
    "\n",
    "# Target: P(Y=1 | do(X=1))\n",
    "obs_only.set_estimand(obs_only.query('Y(X=1)=1'))\n",
    "\n",
    "prog_obs = obs_only.write_program()\n",
    "lb_obs, ub_obs = prog_obs.run_pyomo('glpk', verbose=False)   # linear → LP solver is best\n",
    "print(f\"[OBS only]  P(Y=1 | do(X=1)) ∈ [{lb_obs:.4f}, {ub_obs:.4f}]\")\n",
    "print(f\"W = {ub_obs - lb_obs:.4f}\")\n",
    "\n",
    "# ---------- 4) Problem B: observational + do(Z) ----------\n",
    "obs_plus_doZ = causalProblem(dag, number_values={'Z':2,'X':2,'Y':2})\n",
    "\n",
    "# Add the same observational joint\n",
    "for z in (0, 1):\n",
    "    for x in (0, 1):\n",
    "        for y in (0, 1):\n",
    "            p = float(obs_tab[z, x, y])\n",
    "            obs_plus_doZ.add_constraint(obs_plus_doZ.query(f'Z={z}&X={x}&Y={y}') - Query(p))\n",
    "\n",
    "obs_plus_doZ.add_prob_constraints()\n",
    "\n",
    "# Add uniform (or synthetic) P(X,Y | do(Z=z)) from doZ_tabs\n",
    "# Here we use the *synthetic* doZ we generated above\n",
    "for z in (0, 1):\n",
    "    for x in (0, 1):\n",
    "        for y in (0, 1):\n",
    "            p = float(doZ_tabs[z][x, y])\n",
    "            # Encode P(X=x, Y=y | do(Z=z)) with potential outcomes\n",
    "            lhs = obs_plus_doZ.query(f'X(Z={z})={x}&Y(Z={z})={y}')\n",
    "            obs_plus_doZ.add_constraint(lhs - Query(p))\n",
    "\n",
    "# Same target\n",
    "obs_plus_doZ.set_estimand(obs_plus_doZ.query('Y(X=1)=1'))\n",
    "\n",
    "prog_doZ = obs_plus_doZ.write_program()\n",
    "lb_doZ, ub_doZ = prog_doZ.run_pyomo('glpk', verbose=False)\n",
    "print(f\"[OBS + do(Z)] P(Y=1 | do(X=1)) ∈ [{lb_doZ:.4f}, {ub_doZ:.4f}]\")\n",
    "print(f\"W = {ub_doZ - lb_doZ:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad37e1",
   "metadata": {},
   "source": [
    "## DAG 1\n",
    "Variables: X, Y, Z, W\n",
    "Directed edges:\n",
    "\n",
    "Z → W\n",
    "Z → Y\n",
    "W → X\n",
    "W → Y\n",
    "X → Y\n",
    "\n",
    "Bidirected edge:\n",
    "\n",
    "X ↔ Y (representing unmeasured confounding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth P(Y=1 | do(X=1)) = 0.9000\n",
      "Obs only: [0.6000, 0.9000], W = 0.3000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 159\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGround truth P(Y=1 | do(X=1)) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    157\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObs only: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mub\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m], W = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mub\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mlb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m min_prob, _ = build_lp(\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, doZ=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    160\u001b[39m min_status = min_prob.solve(pulp.PULP_CBC_CMD(msg=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    161\u001b[39m lb = pulp.value(min_prob.objective)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mbuild_lp\u001b[39m\u001b[34m(sense, doZ)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m doZ:\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# ------------- Interventional constraints do(Z=z0) -------------\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# For do(Z=z0), we clamp Z=z0 externally, so we must sum over BOTH latent z=0 and z=1 types.\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m z0 \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m (w,x,y), p \u001b[38;5;129;01min\u001b[39;00m doZ[z0].items():\n\u001b[32m    122\u001b[39m             prob += (\n\u001b[32m    123\u001b[39m                 pulp.lpSum(\n\u001b[32m    124\u001b[39m                     theta[z_lat][iW][iXY]\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m                 ) == p\n\u001b[32m    132\u001b[39m             ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdoZ\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# ------------- Objective: P(Y=1 | do(X=1)) -------------\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Under do(X=1), we clamp X=1; Z stays as drawn; W = W(Z); Y = Y(Z, W(Z), 1)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# pip install pulp if needed\n",
    "from itertools import product\n",
    "import pulp\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Problem data (from prompt)\n",
    "# -----------------------------\n",
    "# DAG structure:\n",
    "# U_X_Y -> X, U_X_Y -> Y, Z -> W, Z -> Y, W -> X, W -> Y, X -> Y\n",
    "# (We encode unobserved confounding between X and Y via joint response function types for the c-component {X,Y}.)\n",
    "\n",
    "# Observational P(Z,W,X,Y)  (16 cells)\n",
    "obs = {\n",
    " (0,0,0,0): 0.0,\n",
    " (0,0,0,1): 0.0,\n",
    " (0,0,1,0): 0.0,\n",
    " (0,0,1,1): 0.0,\n",
    " (0,1,0,0): 0.0,\n",
    " (0,1,0,1): 0.0,\n",
    " (0,1,1,0): 0.0,\n",
    " (0,1,1,1): 0.6,\n",
    " (1,0,0,0): 0.0,\n",
    " (1,0,0,1): 0.3,\n",
    " (1,0,1,0): 0.1,\n",
    " (1,0,1,1): 0.0,\n",
    " (1,1,0,0): 0.0,\n",
    " (1,1,0,1): 0.0,\n",
    " (1,1,1,0): 0.0,\n",
    " (1,1,1,1): 0.0,\n",
    "}\n",
    "# Sanity: sums to 1\n",
    "assert abs(sum(obs.values()) - 1.0) < 1e-12\n",
    "\n",
    "# Interventional P(W,X,Y | do(Z=z))\n",
    "doZ = {\n",
    " 0: {(0,0,0):0.0, (0,0,1):0.0, (0,1,0):0.0, (0,1,1):0.0,\n",
    "     (1,0,0):0.0, (1,0,1):0.1, (1,1,0):0.0, (1,1,1):0.9},\n",
    " 1: {(0,0,0):0.0, (0,0,1):0.9, (0,1,0):0.1, (0,1,1):0.0,\n",
    "     (1,0,0):0.0, (1,0,1):0.0, (1,1,0):0.0, (1,1,1):0.0},\n",
    "}\n",
    "# sums to 1 per z\n",
    "for z in [0,1]:\n",
    "    assert abs(sum(doZ[z].values()) - 1.0) < 1e-12\n",
    "\n",
    "# Ground truth for reference (not used by the LP objective directly; we will bound it)\n",
    "gt = 0.9\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Enumerate response-function type space\n",
    "# -----------------------------------------\n",
    "# W response types: W: {0,1} -> {0,1}\n",
    "W_types = [(w0, w1) for w0, w1 in product([0,1],[0,1])]  # 4 types\n",
    "\n",
    "# X response types: X: {w} -> {0,1}\n",
    "X_types = [(x0, x1) for x0, x1 in product([0,1],[0,1])]  # 4 types, x(w)=xw\n",
    "\n",
    "# Y response types: Y: {z,w,x} -> {0,1}  (8 inputs)\n",
    "# encode by tuple (y000, y001, y010, y011, y100, y101, y110, y111) in lex order (z,w,x)\n",
    "def idx3(z,w,x): return (z<<2)|(w<<1)|x\n",
    "Y_types = []\n",
    "for bits in product([0,1], repeat=8):\n",
    "    Y_types.append(tuple(bits))  # 256 types\n",
    "\n",
    "# XY c-component type = (X_type, Y_type)\n",
    "XY_types = [(xt, yt) for xt in X_types for yt in Y_types]  # 4*256 = 1024\n",
    "\n",
    "# Helper evaluators\n",
    "def W_of(tW, z):\n",
    "    w0,w1 = tW\n",
    "    return w0 if z==0 else w1\n",
    "\n",
    "def X_of(tXY, w):\n",
    "    xt, yt = tXY\n",
    "    x0,x1 = xt\n",
    "    return x0 if w==0 else x1\n",
    "\n",
    "def Y_of(tXY, z, w, x):\n",
    "    xt, yt = tXY\n",
    "    return yt[idx3(z,w,x)]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3) Decision vars θ[z, tW, tXY] >= 0, sum to 1\n",
    "# ---------------------------------------------\n",
    "# Indices\n",
    "Z_vals   = [0,1]\n",
    "W_T_idx  = list(range(len(W_types)))\n",
    "XY_T_idx = list(range(len(XY_types)))\n",
    "\n",
    "# Create LP problem factory\n",
    "def build_lp(sense='min', do_Z=False):\n",
    "    prob = pulp.LpProblem(\"Bounds_P_Y1_doX1\", pulp.LpMinimize if sense=='min' else pulp.LpMaximize)\n",
    "\n",
    "    theta = pulp.LpVariable.dicts(\n",
    "        \"theta\",\n",
    "        (Z_vals, W_T_idx, XY_T_idx),\n",
    "        lowBound=0.0, upBound=None, cat='Continuous'\n",
    "    )\n",
    "\n",
    "    # Sum-to-one\n",
    "    prob += pulp.lpSum(theta[z][iW][iXY] for z in Z_vals for iW in W_T_idx for iXY in XY_T_idx) == 1.0, \"total_prob\"\n",
    "\n",
    "    # ------------- Observational constraints -------------\n",
    "    # For each (z,w,x,y): sum types producing that outcome must equal P(z,w,x,y)\n",
    "    for (z,w,x,y), p in obs.items():\n",
    "        prob += (\n",
    "            pulp.lpSum(\n",
    "                theta[z][iW][iXY]\n",
    "                for iW in W_T_idx\n",
    "                for iXY in XY_T_idx\n",
    "                if (W_of(W_types[iW], z) == w) and\n",
    "                   (X_of(XY_types[iXY], w) == x) and\n",
    "                   (Y_of(XY_types[iXY], z, w, x) == y)\n",
    "            ) == p\n",
    "        ), f\"obs_{z}{w}{x}{y}\"\n",
    "\n",
    "\n",
    "    if do_Z:\n",
    "        # ------------- Interventional constraints do(Z=z0) -------------\n",
    "        # For do(Z=z0), we clamp Z=z0 externally, so we must sum over BOTH latent z=0 and z=1 types.\n",
    "        for z0 in [0,1]:\n",
    "            for (w,x,y), p in doZ[z0].items():\n",
    "                prob += (\n",
    "                    pulp.lpSum(\n",
    "                        theta[z_lat][iW][iXY]\n",
    "                        for z_lat in [0,1]           # sum over original Z-types\n",
    "                        for iW in W_T_idx\n",
    "                        for iXY in XY_T_idx\n",
    "                        if (W_of(W_types[iW], z0) == w) and\n",
    "                        (X_of(XY_types[iXY], w) == x) and\n",
    "                        (Y_of(XY_types[iXY], z0, w, x) == y)\n",
    "                    ) == p\n",
    "                ), f\"doZ{z0}_{w}{x}{y}\"\n",
    "\n",
    "    # ------------- Objective: P(Y=1 | do(X=1)) -------------\n",
    "    # Under do(X=1), we clamp X=1; Z stays as drawn; W = W(Z); Y = Y(Z, W(Z), 1)\n",
    "    obj = pulp.lpSum(\n",
    "        theta[z][iW][iXY] *\n",
    "        (1 if Y_of(XY_types[iXY], z, W_of(W_types[iW], z), 1) == 1 else 0)\n",
    "        for z in Z_vals for iW in W_T_idx for iXY in XY_T_idx\n",
    "    )\n",
    "    prob += obj, \"P_Y1_doX1\"\n",
    "\n",
    "    return prob, theta\n",
    "\n",
    "# --------------------------\n",
    "# 4) Solve min and max bounds\n",
    "# --------------------------\n",
    "min_prob_obs, _ = build_lp('min', do_Z=False)\n",
    "min_status = min_prob_obs.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "lb = pulp.value(min_prob_obs.objective)\n",
    "\n",
    "max_prob_obs, _ = build_lp('max', do_Z=False)\n",
    "max_status = max_prob_obs.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "ub = pulp.value(max_prob_obs.objective)\n",
    "\n",
    "print(f\"Ground truth P(Y=1 | do(X=1)) = {gt:.4f}\")\n",
    "print(f\"Obs only: [{lb:.4f}, {ub:.4f}], W = {ub - lb:.4f}\")\n",
    "\n",
    "min_prob, _ = build_lp('min', do_Z=True)\n",
    "min_status = min_prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "lb = pulp.value(min_prob.objective)\n",
    "\n",
    "max_prob, _ = build_lp('max', do_Z=True)\n",
    "max_status = max_prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "ub = pulp.value(max_prob.objective)\n",
    "\n",
    "print(f\"doZ + Obs: [{lb:.4f}, {ub:.4f}], W = {ub - lb:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
