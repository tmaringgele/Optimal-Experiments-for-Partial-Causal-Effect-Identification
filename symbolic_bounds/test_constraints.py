"""
Test function to verify that constraints generated by Algorithm 1 are logically consistent.

This module provides validation to ensure that for each constraint equation:
    p*(configuration) = sum of q[γ] for all compatible response types

A response type γ is "compatible" with a configuration if it does not contradict
the observed values. For example:
    - p*(X=1, Y=0) = q[0] + q[2]
    - q[0] corresponds to Y: [(X=0)→0, (X=1)→0]
    - q[2] corresponds to Y: [(X=0)→1, (X=1)→0]
    
Both response types are compatible with (X=1, Y=0) because:
    - q[0]: when X=1, Y→0 (matches observed Y=0) ✓
    - q[2]: when X=1, Y→0 (matches observed Y=0) ✓
    
A contradiction would be if we included q[1] = Y: [(X=0)→0, (X=1)→1]
because when X=1, this would produce Y=1, contradicting observed Y=0.
"""

from typing import Dict, List, Tuple
import numpy as np
from .dag import DAG
from .node import Node
from .response_type import ResponseType
from .constraints import Constraints
from .program_factory import ProgramFactory
from .random_dag_generator import generate_random_partitioned_dag, generate_random_chain_dag, generate_random_tree_dag


def validate_constraints(dag: DAG, verbose: bool = False) -> bool:
    """
    Validate that all constraints generated for a DAG are logically consistent.
    
    This function verifies that:
    1. For each configuration (w_L, w_R), only compatible response types are included
    2. A response type γ is compatible if simulating it with the given w_L produces w_R
    3. No contradictions exist in the constraint equations
    
    The validation works by:
    - Generating constraints using Algorithm 1
    - For each row b in matrix P (corresponding to configuration (w_{b,L}, w_{b,R}))
    - Checking that P[b, γ] = 1 only when response type γ is truly compatible
    - Verifying compatibility by simulating the response type with observed values
    
    Args:
        dag: The causal DAG to validate constraints for.
        verbose: If True, print detailed validation information.
    
    Returns:
        True if all constraints are valid (no contradictions found), False otherwise.
    
    Example:
        >>> dag = DAG()
        >>> X = dag.add_node('X', support={0, 1}, partition='L')
        >>> Y = dag.add_node('Y', support={0, 1}, partition='R')
        >>> dag.add_edge(X, Y)
        >>> dag.generate_all_response_types()
        >>> assert validate_constraints(dag, verbose=True)
    """
    if verbose:
        print("=" * 80)
        print("VALIDATING CONSTRAINTS FOR DAG")
        print("=" * 80)
        print(f"Nodes in W_L: {', '.join(n.name for n in sorted(dag.W_L, key=lambda x: x.name))}")
        print(f"Nodes in W_R: {', '.join(n.name for n in sorted(dag.W_R, key=lambda x: x.name))}")
        print(f"Edges: {', '.join(f'{p.name}->{c.name}' for p, c in sorted(dag.edges, key=lambda e: (e[0].name, e[1].name)))}")
    
    # Generate all response types
    all_response_types = dag.generate_all_response_types()
    
    # Generate constraints using Algorithm 1
    constraints = ProgramFactory.write_constraints(dag)
    
    if verbose:
        print("\n" + "=" * 80)
        print("GENERATED CONSTRAINTS")
        print("=" * 80)
        constraints.print_constraints(show_matrices=False, explicit_equations=True)
    
    # Validate joint probability constraints (P matrix)
    valid_joint = _validate_joint_constraints(dag, constraints, all_response_types, verbose)
    
    # Validate conditional probability constraints (Lambda matrices)
    valid_conditional = _validate_conditional_constraints(dag, constraints, all_response_types, verbose)
    
    if verbose:
        print("\n" + "=" * 80)
        print("VALIDATION RESULT")
        print("=" * 80)
        if valid_joint and valid_conditional:
            print("✓ ALL CONSTRAINTS ARE VALID - NO CONTRADICTIONS FOUND")
        else:
            print("✗ VALIDATION FAILED - CONTRADICTIONS DETECTED")
            if not valid_joint:
                print("  - Joint probability constraints contain errors")
            if not valid_conditional:
                print("  - Conditional probability constraints contain errors")
        print("=" * 80)
    
    return valid_joint and valid_conditional


def _validate_joint_constraints(dag: DAG, constraints: Constraints, 
                                all_response_types: Dict[Node, List[ResponseType]],
                                verbose: bool) -> bool:
    """
    Validate joint probability constraints: P * q = p*.
    
    For each configuration b (row in P matrix):
    - Get the configuration (w_{b,L}, w_{b,R})
    - For each response type γ where P[b, γ] = 1:
      * Verify that γ is truly compatible with the configuration
      * Check that simulating γ with w_{b,L} produces w_{b,R}
    
    Args:
        dag: The causal DAG.
        constraints: Generated constraint system.
        all_response_types: All response types for all nodes.
        verbose: If True, print detailed validation info.
    
    Returns:
        True if all joint constraints are valid, False otherwise.
    """
    if verbose:
        print("\n" + "-" * 80)
        print("VALIDATING JOINT PROBABILITY CONSTRAINTS (P matrix)")
        print("-" * 80)
    
    all_nodes = sorted(dag.get_all_nodes(), key=lambda n: n.name)
    w_l_nodes = sorted(dag.W_L, key=lambda n: n.name)
    w_r_nodes = sorted(dag.W_R, key=lambda n: n.name)
    
    # Reverse mapping: from index to configuration
    index_to_config = {idx: config for config, idx in constraints.joint_prob_index.items()}
    
    # Reverse mapping: from index to response type combination
    index_to_rt = {idx: rt_combo for rt_combo, idx in constraints.response_type_index.items()}
    
    all_valid = True
    num_checked = 0
    num_equations = 0
    
    # For each configuration b
    for b in range(constraints.P.shape[0]):
        config = index_to_config[b]
        config_dict = dict(config)
        
        # Extract w_{b,L} and w_{b,R}
        w_b_L = {node: config_dict[node] for node in w_l_nodes}
        w_b_R = {node: config_dict[node] for node in w_r_nodes}
        
        # Find which response types have P[b, γ] = 1
        compatible_indices = np.where(constraints.P[b, :] == 1)[0]
        
        if len(compatible_indices) == 0:
            continue  # No response types for this configuration (shouldn't happen)
        
        num_equations += 1
        
        if verbose and num_equations <= 5:  # Show first few equations
            config_label = constraints.joint_prob_labels[b]
            print(f"\nConfiguration {b}: {config_label}")
            rt_labels = [constraints.response_type_labels[γ] for γ in compatible_indices]
            print(f"  Compatible response types: {', '.join(f'q[{γ}]' for γ in compatible_indices)}")
        
        # Validate each compatible response type
        for gamma in compatible_indices:
            rt_combo = index_to_rt[gamma]  # Response type combination for W_R
            
            # Check compatibility by simulating the response type
            is_valid = _check_response_type_compatibility(
                dag, all_nodes, all_response_types,
                w_r_nodes, rt_combo, config_dict
            )
            
            num_checked += 1
            
            if not is_valid:
                all_valid = False
                print(f"\n✗ CONTRADICTION FOUND!")
                print(f"  Configuration: {constraints.joint_prob_labels[b]}")
                print(f"  Response type γ={gamma}: {constraints.response_type_labels[gamma]}")
                print(f"  This response type is marked compatible (P[{b}, {gamma}] = 1)")
                print(f"  but it contradicts the observed configuration!")
                
                # Show why it's incompatible
                _explain_incompatibility(dag, w_r_nodes, rt_combo, w_b_L, w_b_R)
    
    if verbose:
        print(f"\n  Checked {num_checked} compatibility entries across {num_equations} equations")
        if all_valid:
            print("  ✓ All joint probability constraints are valid")
    
    return all_valid


def _validate_conditional_constraints(dag: DAG, constraints: Constraints,
                                      all_response_types: Dict[Node, List[ResponseType]],
                                      verbose: bool) -> bool:
    """
    Validate conditional probability constraints: Lambda * q = p.
    
    For each W_L configuration and each W_R configuration:
    - Verify that included response types are compatible with P(W_R | W_L)
    
    Args:
        dag: The causal DAG.
        constraints: Generated constraint system.
        all_response_types: All response types for all nodes.
        verbose: If True, print detailed validation info.
    
    Returns:
        True if all conditional constraints are valid, False otherwise.
    """
    if verbose:
        print("\n" + "-" * 80)
        print("VALIDATING CONDITIONAL PROBABILITY CONSTRAINTS (Λ matrices)")
        print("-" * 80)
    
    all_nodes = sorted(dag.get_all_nodes(), key=lambda n: n.name)
    w_r_nodes = sorted(dag.W_R, key=lambda n: n.name)
    
    # Reverse mapping: from index to response type combination
    index_to_rt = {idx: rt_combo for rt_combo, idx in constraints.response_type_index.items()}
    
    all_valid = True
    num_checked = 0
    num_conditions = len(constraints.Lambda)
    
    # For each W_L configuration
    for condition_idx, (condition_name, P_lambda) in enumerate(constraints.Lambda.items()):
        if verbose and condition_idx < 3:  # Show first few conditions
            print(f"\nCondition: {condition_name}")
        
        cond_labels = constraints.conditional_prob_labels[condition_name]
        cond_index = constraints.conditional_prob_index[condition_name]
        
        # Reverse mapping for this condition
        index_to_w_r_config = {idx: config for config, idx in cond_index.items()}
        
        # For each W_R configuration
        for config_idx in range(P_lambda.shape[0]):
            w_r_config = index_to_w_r_config[config_idx]
            
            # Find compatible response types
            compatible_indices = np.where(P_lambda[config_idx, :] == 1)[0]
            
            if len(compatible_indices) == 0:
                continue
            
            # Extract W_L values from condition name
            # condition_name format: "W_L=(X=1)" or "W_L=(Z=0, X=1)"
            w_l_name_dict = _parse_condition_name(condition_name)
            
            # Convert node names to Node objects
            w_l_nodes_list = sorted(dag.W_L, key=lambda n: n.name)
            w_l_dict = {node: w_l_name_dict[node.name] for node in w_l_nodes_list}
            
            # Build full configuration
            w_r_dict = dict(w_r_config)
            full_config_dict = {**w_l_dict, **w_r_dict}
            
            if verbose and condition_idx < 3 and config_idx < 2:
                print(f"  {cond_labels[config_idx]}")
                rt_labels = [constraints.response_type_labels[γ] for γ in compatible_indices]
                print(f"    Compatible: {', '.join(f'q[{γ}]' for γ in compatible_indices)}")
            
            # Validate each compatible response type
            for gamma in compatible_indices:
                rt_combo = index_to_rt[gamma]
                
                is_valid = _check_response_type_compatibility(
                    dag, all_nodes, all_response_types,
                    w_r_nodes, rt_combo, full_config_dict
                )
                
                num_checked += 1
                
                if not is_valid:
                    all_valid = False
                    print(f"\n✗ CONTRADICTION FOUND in conditional constraint!")
                    print(f"  Condition: {condition_name}")
                    print(f"  Configuration: {cond_labels[config_idx]}")
                    print(f"  Response type γ={gamma}: {constraints.response_type_labels[gamma]}")
                    print(f"  Marked compatible but contradicts observation!")
    
    if verbose:
        print(f"\n  Checked {num_checked} compatibility entries across {num_conditions} conditions")
        if all_valid:
            print("  ✓ All conditional probability constraints are valid")
    
    return all_valid


def _check_response_type_compatibility(dag: DAG, all_nodes: List[Node],
                                       all_response_types: Dict[Node, List[ResponseType]],
                                       w_r_nodes: List[Node],
                                       rt_combo: Tuple[ResponseType, ...],
                                       config_dict: Dict[Node, int]) -> bool:
    """
    Check if a response type combination is compatible with a configuration.
    
    A response type γ (for W_R) is compatible with (w_L, w_R) if:
    - For each node W^i in W_R:
      * Simulating g^{W^i}(Pa(W^i), r_γ) with parent values from config produces w_R[i]
    
    This is the same compatibility check used in Algorithm 1.
    
    Args:
        dag: The causal DAG.
        all_nodes: All nodes in the DAG.
        all_response_types: All response types for all nodes.
        w_r_nodes: Nodes in W_R.
        rt_combo: Response type combination (for W_R nodes).
        config_dict: Full configuration {node: value} for all nodes.
    
    Returns:
        True if compatible, False if contradicts.
    """
    rt_map = dict(zip(w_r_nodes, rt_combo))
    
    # For each W_R node, check if response type produces the observed value
    for node in w_r_nodes:
        rt = rt_map[node]
        observed_value = config_dict[node]
        
        # Get parent values from configuration
        parents = dag.get_parents(node)
        
        if not parents:
            # No parents: check if response type produces observed value
            if rt.get(()) != observed_value:
                return False
        else:
            # Build parent configuration from observed values
            parent_config = tuple((parent, config_dict[parent])
                                 for parent in sorted(parents, key=lambda n: n.name))
            
            # Check if response type produces observed value given parents
            try:
                produced_value = rt.get(parent_config)
                if produced_value != observed_value:
                    return False
            except KeyError:
                # Response type doesn't cover this parent configuration
                return False
    
    return True


def _explain_incompatibility(dag: DAG, w_r_nodes: List[Node],
                             rt_combo: Tuple[ResponseType, ...],
                             w_b_L: Dict[Node, int], w_b_R: Dict[Node, int]) -> None:
    """
    Explain why a response type is incompatible with a configuration.
    
    Args:
        dag: The causal DAG.
        w_r_nodes: Nodes in W_R.
        rt_combo: Response type combination.
        w_b_L: Observed values for W_L.
        w_b_R: Observed values for W_R.
    """
    rt_map = dict(zip(w_r_nodes, rt_combo))
    
    print("\n  Detailed analysis:")
    for node in w_r_nodes:
        rt = rt_map[node]
        observed = w_b_R[node]
        
        parents = dag.get_parents(node)
        if not parents:
            produced = rt.get(())
            print(f"    {node.name}: response type produces {produced}, observed {observed}")
        else:
            parent_config = tuple((parent, w_b_L.get(parent, w_b_R.get(parent)))
                                 for parent in sorted(parents, key=lambda n: n.name))
            try:
                produced = rt.get(parent_config)
                parent_str = ", ".join(f"{p.name}={v}" for p, v in parent_config)
                print(f"    {node.name}: given ({parent_str}), produces {produced}, observed {observed}")
            except KeyError:
                print(f"    {node.name}: response type doesn't cover this parent configuration")


def _parse_condition_name(condition_name: str) -> Dict[Node, int]:
    """
    Parse condition name to extract W_L configuration.
    
    Args:
        condition_name: String like "W_L=(X=1)" or "W_L=(Z=0, X=1)".
    
    Returns:
        Dictionary mapping node names to values (note: returns str keys, not Node objects).
    """
    # Extract content between parentheses
    content = condition_name.split("(")[1].split(")")[0]
    
    # Parse assignments
    assignments = content.split(", ")
    w_l_dict = {}
    
    for assignment in assignments:
        node_name, value_str = assignment.split("=")
        w_l_dict[node_name] = int(value_str)
    
    return w_l_dict


def test_simple_chain():
    """Test validation with simple X -> Y chain."""
    print("\n" + "=" * 80)
    print("TEST: Simple Chain X -> Y")
    print("=" * 80)
    
    dag = DAG()
    X = dag.add_node('X', support={0, 1}, partition='L')
    Y = dag.add_node('Y', support={0, 1}, partition='R')
    dag.add_edge(X, Y)
    dag.generate_all_response_types()
    
    result = validate_constraints(dag, verbose=True)
    
    if result:
        print("\n✓ TEST PASSED: Simple chain validated successfully")
    else:
        print("\n✗ TEST FAILED: Simple chain validation found errors")
    
    return result


def test_confounding():
    """Test validation with confounded structure Z -> X -> Y, Z -> Y."""
    print("\n" + "=" * 80)
    print("TEST: Confounding Z -> X -> Y, Z -> Y")
    print("=" * 80)
    
    dag = DAG()
    Z = dag.add_node('Z', support={0, 1}, partition='L')
    X = dag.add_node('X', support={0, 1}, partition='L')
    Y = dag.add_node('Y', support={0, 1}, partition='R')
    dag.add_edge(Z, X)
    dag.add_edge(Z, Y)
    dag.add_edge(X, Y)
    dag.generate_all_response_types()
    
    result = validate_constraints(dag, verbose=True)
    
    if result:
        print("\n✓ TEST PASSED: Confounding structure validated successfully")
    else:
        print("\n✗ TEST FAILED: Confounding structure validation found errors")
    
    return result


def test_incompatibility_detection():
    """
    Test that the validation function correctly detects incompatible constraints.
    
    This test intentionally creates an invalid constraint by manually corrupting
    the P matrix to include an incompatible response type.
    """
    print("\n" + "=" * 80)
    print("TEST: Incompatibility Detection (Negative Test)")
    print("=" * 80)
    
    # Create simple X -> Y DAG
    dag = DAG()
    X = dag.add_node('X', support={0, 1}, partition='L')
    Y = dag.add_node('Y', support={0, 1}, partition='R')
    dag.add_edge(X, Y)
    dag.generate_all_response_types()
    
    # Generate constraints normally
    all_response_types = dag.generate_all_response_types()
    constraints = ProgramFactory.write_constraints(dag)
    
    print("\nOriginal constraint (should be valid):")
    print("  p*(X=1, Y=0) = q[0] + q[2]")
    print("  - q[0]: Y: [(X=0)→0, (X=1)→0] ✓ compatible")
    print("  - q[2]: Y: [(X=0)→1, (X=1)→0] ✓ compatible")
    
    # Now corrupt the constraint by adding an incompatible response type
    # Configuration X=1, Y=0 is at index 2 in the P matrix
    # Response type q[1] = Y: [(X=0)→0, (X=1)→1] should NOT be compatible
    # because when X=1, it produces Y=1, but we observe Y=0
    
    print("\nCorrupting constraint by adding incompatible response type:")
    print("  p*(X=1, Y=0) = q[0] + q[1] + q[2]  <- q[1] is WRONG!")
    print("  - q[0]: Y: [(X=0)→0, (X=1)→0] ✓ compatible")
    print("  - q[1]: Y: [(X=0)→0, (X=1)→1] ✗ INCOMPATIBLE (X=1 → Y=1, but observe Y=0)")
    print("  - q[2]: Y: [(X=0)→1, (X=1)→0] ✓ compatible")
    
    # Manually corrupt the P matrix
    # Before: P[2, :] = [1, 0, 1, 0] for config (X=1, Y=0)
    # After:  P[2, :] = [1, 1, 1, 0] <- adding q[1] which is incompatible
    constraints.P[2, 1] = 1.0
    
    print("\nRunning validation on corrupted constraints...")
    
    # Validate - should FAIL
    result = _validate_joint_constraints(dag, constraints, all_response_types, verbose=True)
    
    if not result:
        print("\n✓ TEST PASSED: Validation correctly detected the incompatible constraint!")
        return True
    else:
        print("\n✗ TEST FAILED: Validation did NOT detect the incompatible constraint!")
        return False


def test_random_dags(num_tests: int = 20, max_nodes: int = 6, verbose: bool = False) -> bool:
    """
    Test Algorithm 1 implementation on randomly generated DAGs.
    
    This stress test generates many random DAG structures and validates that
    the constraints produced are logically consistent. This helps ensure the
    implementation is robust and correct across a wide variety of graph structures.
    
    Args:
        num_tests: Number of random DAGs to test.
        max_nodes: Maximum number of nodes in generated DAGs.
        verbose: If True, print details for each test.
    
    Returns:
        True if all random DAGs pass validation, False otherwise.
    """
    print("\n" + "=" * 80)
    print(f"TEST: Random DAGs (n={num_tests} tests, up to {max_nodes} nodes)")
    print("=" * 80)
    
    passed = 0
    failed = 0
    failed_cases = []
    
    # Test different types of random DAGs
    test_configs = [
        ("random", lambda n, s: generate_random_partitioned_dag(n, seed=s)),
        # ("chain", lambda n, s: generate_random_chain_dag(n, seed=s)),
        # ("tree", lambda n, s: generate_random_tree_dag(n, seed=s)),
    ]
    
    test_idx = 0
    for dag_type, generator in test_configs:
        for i in range(num_tests // len(test_configs)):
            test_idx += 1
            n_nodes = np.random.randint(3, max_nodes + 1)
            seed = test_idx * 100 + i
            
            try:
                # Generate random DAG
                dag = generator(n_nodes, seed)
                dag.generate_all_response_types()
                
                # Count response types (for info)
                all_response_types = dag.generate_all_response_types()
                w_r_nodes = sorted(dag.W_R, key=lambda n: n.name)
                
                # Calculate ℵᴿ
                if len(w_r_nodes) == 0:
                    if verbose:
                        print(f"  Test {test_idx} ({dag_type}, n={n_nodes}): SKIPPED (no W_R nodes)")
                    continue
                
                import itertools
                w_r_response_type_lists = [all_response_types[node] for node in w_r_nodes]
                aleph_R = len(list(itertools.product(*w_r_response_type_lists)))
                
                if verbose:
                    print(f"\n  Test {test_idx} ({dag_type}, n={n_nodes}): ", end="")
                    print(f"|W_L|={len(dag.W_L)}, |W_R|={len(dag.W_R)}, ℵᴿ={aleph_R}, edges={len(dag.edges)}")
                
                # Validate constraints
                result = validate_constraints(dag, verbose=False)
                
                if result:
                    passed += 1
                    if verbose:
                        print(f"    ✓ PASSED")
                    elif test_idx % 5 == 0:
                        print(".", end="", flush=True)
                else:
                    failed += 1
                    failed_cases.append({
                        'test_idx': test_idx,
                        'dag_type': dag_type,
                        'n_nodes': n_nodes,
                        'seed': seed,
                        'n_left': len(dag.W_L),
                        'n_right': len(dag.W_R),
                        'aleph_R': aleph_R,
                        'edges': len(dag.edges)
                    })
                    print(f"\n    ✗ FAILED")
                    
            except Exception as e:
                failed += 1
                print(f"\n  Test {test_idx} EXCEPTION: {type(e).__name__}: {e}")
                failed_cases.append({
                    'test_idx': test_idx,
                    'dag_type': dag_type,
                    'exception': str(e)
                })
    
    # Fill remaining tests with random DAGs
    while test_idx < num_tests:
        test_idx += 1
        n_nodes = np.random.randint(3, max_nodes + 1)
        seed = test_idx * 100
        
        try:
            dag = generate_random_partitioned_dag(n_nodes, seed=seed)
            dag.generate_all_response_types()
            
            w_r_nodes = sorted(dag.W_R, key=lambda n: n.name)
            if len(w_r_nodes) == 0:
                continue
            
            result = validate_constraints(dag, verbose=False)
            
            if result:
                passed += 1
                if test_idx % 5 == 0:
                    print(".", end="", flush=True)
            else:
                failed += 1
                failed_cases.append({'test_idx': test_idx, 'n_nodes': n_nodes, 'seed': seed})
                
        except Exception as e:
            failed += 1
            failed_cases.append({'test_idx': test_idx, 'exception': str(e)})
    
    print()  # Newline after progress dots
    
    # Print summary
    print(f"\n{'Results':^80}")
    print("-" * 80)
    print(f"  Tests run:    {passed + failed}")
    print(f"  Passed:       {passed} ✓")
    print(f"  Failed:       {failed} ✗")
    
    if failed > 0:
        print(f"\n  Failed cases:")
        for case in failed_cases[:5]:  # Show first 5 failures
            print(f"    - Test {case.get('test_idx', '?')}: {case}")
        if len(failed_cases) > 5:
            print(f"    ... and {len(failed_cases) - 5} more")
    
    if passed == passed + failed and failed == 0:
        print(f"\n✓ TEST PASSED: All {passed} random DAGs validated successfully!")
        return True
    else:
        success_rate = 100 * passed / (passed + failed) if (passed + failed) > 0 else 0
        print(f"\n  Success rate: {success_rate:.1f}%")
        if success_rate >= 95:
            print(f"✓ TEST PASSED: High success rate on random DAGs")
            return True
        else:
            print(f"✗ TEST FAILED: Too many failures on random DAGs")
            return False


if __name__ == "__main__":
    """Run validation tests."""
    print("RUNNING CONSTRAINT VALIDATION TESTS")
    print("=" * 80)
    
    # Test 1: Simple chain
    test1_passed = test_simple_chain()
    
    # Test 2: Confounding
    test2_passed = test_confounding()
    
    # Test 3: Incompatibility detection (negative test)
    test3_passed = test_incompatibility_detection()
    
    # Test 4: Random DAGs (stress test)
    test4_passed = test_random_dags(num_tests=1, max_nodes=10, verbose=False)
    
    # Summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)
    print(f"Simple Chain (X -> Y):              {'PASSED ✓' if test1_passed else 'FAILED ✗'}")
    print(f"Confounding (Z -> X -> Y, Z -> Y):  {'PASSED ✓' if test2_passed else 'FAILED ✗'}")
    print(f"Incompatibility Detection:          {'PASSED ✓' if test3_passed else 'FAILED ✗'}")
    print(f"Random DAGs (15 tests):             {'PASSED ✓' if test4_passed else 'FAILED ✗'}")
    
    if test1_passed and test2_passed and test3_passed and test4_passed:
        print("\n✓ ALL TESTS PASSED - Algorithm 1 implementation is correct!")
    else:
        print("\n✗ SOME TESTS FAILED - Algorithm 1 implementation has errors")
